{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('')\n",
    "df['content'] = df['author'] + ' ' + df['title'] + ' ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['text', 'author', 'title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Consortiumnews.com Why the Truth Might Get You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Purkiss 15 Civilians Killed In Single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Howard Portnoy Iranian woman jailed for fictio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                            content\n",
       "0   0      1  Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
       "1   1      0  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
       "2   2      1  Consortiumnews.com Why the Truth Might Get You...\n",
       "3   3      1  Jessica Purkiss 15 Civilians Killed In Single ...\n",
       "4   4      1  Howard Portnoy Iranian woman jailed for fictio..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10387.0</td>\n",
       "      <td>10392.644171</td>\n",
       "      <td>5982.025154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5225.5</td>\n",
       "      <td>10396.0</td>\n",
       "      <td>15565.5</td>\n",
       "      <td>20797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10413.0</td>\n",
       "      <td>10406.338711</td>\n",
       "      <td>6027.288133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5159.0</td>\n",
       "      <td>10403.0</td>\n",
       "      <td>15629.0</td>\n",
       "      <td>20799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                                            \\\n",
       "         count          mean          std  min     25%      50%      75%   \n",
       "label                                                                      \n",
       "0      10387.0  10392.644171  5982.025154  1.0  5225.5  10396.0  15565.5   \n",
       "1      10413.0  10406.338711  6027.288133  0.0  5159.0  10403.0  15629.0   \n",
       "\n",
       "                \n",
       "           max  \n",
       "label           \n",
       "0      20797.0  \n",
       "1      20799.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "def process_text(mess):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funny one liner version\n",
    "text_process = lambda mess: [word for word in ''.join([char for char in mess if char not in string.punctuation]).split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Darrell, Lucus, House, Dem, Aide, Didn’t, Eve...\n",
       "1    [Daniel, J, Flynn, FLYNN, Hillary, Clinton, Bi...\n",
       "2    [Consortiumnewscom, Truth, Might, Get, Fired, ...\n",
       "3    [Jessica, Purkiss, 15, Civilians, Killed, Sing...\n",
       "4    [Howard, Portnoy, Iranian, woman, jailed, fict...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].head(5).apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\1kuliah\\sem5\\kk\\fp\\content.ipynb Cell 12\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_words \u001b[39m=\u001b[39m CountVectorizer(analyzer\u001b[39m=\u001b[39;49mtext_process)\u001b[39m.\u001b[39;49mfit(df[\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mU\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(all_words\u001b[39m.\u001b[39mvocabulary_))\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1328\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, raw_documents, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1313\u001b[0m     \u001b[39m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \n\u001b[0;32m   1315\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[39m        Fitted vectorizer.\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1328\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   1329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             )\n\u001b[0;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1264\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1263\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1264\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1265\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1266\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:108\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    106\u001b[0m     doc \u001b[39m=\u001b[39m decoder(doc)\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m analyzer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     doc \u001b[39m=\u001b[39m analyzer(doc)\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32me:\\1kuliah\\sem5\\kk\\fp\\content.ipynb Cell 12\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(mess)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# funny one liner version\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text_process \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m mess: [word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([char \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m mess \u001b[39mif\u001b[39;00m char \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation])\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[1;32me:\\1kuliah\\sem5\\kk\\fp\\content.ipynb Cell 12\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# funny one liner version\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/1kuliah/sem5/kk/fp/content.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text_process \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m mess: [word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([char \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m mess \u001b[39mif\u001b[39;00m char \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string\u001b[39m.\u001b[39mpunctuation])\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m)]\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mjoin(file)\u001b[39m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m FileSystemPathPointer(_path)\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decorator\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[39m=\u001b[39m (args[\u001b[39m0\u001b[39m], add_py3_data(args[\u001b[39m1\u001b[39m])) \u001b[39m+\u001b[39m args[\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m init_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[39m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexists(_path):\n\u001b[0;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file or directory: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m _path\n",
      "File \u001b[1;32mc:\\Users\\CF79A965FBDD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     20\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_words = CountVectorizer(analyzer=text_process).fit(df['content'].values.astype('U'))\n",
    "\n",
    "print(len(all_words.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc00fca6cdcad8921af4323f825e56b156a5d5a8406c5eab17511b3db952a09c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
